WEBVTT

00:00:07.760 --> 00:00:08.720
Good evening everyone

00:00:08.720 --> 00:00:11.160
and welcome at the
Going Digital conference

00:00:11.160 --> 00:00:13.120
at the panel that is called

00:00:13.120 --> 00:00:15.240
“Is the future of democracy digital?”

00:00:15.880 --> 00:00:17.960
At this panel we will discuss

00:00:18.000 --> 00:00:19.280
problems and questions

00:00:19.360 --> 00:00:22.280
that are closely related
to digital agenda

00:00:22.280 --> 00:00:23.560
and digital technologies

00:00:23.800 --> 00:00:27.400
in the context of our democracy
and democratic systems

00:00:27.760 --> 00:00:30.000
Before we move to the introduction
of our panelists

00:00:30.000 --> 00:00:32.320
and before we move to discussion itself,

00:00:32.440 --> 00:00:34.400
please let me tell you
some organizational matters

00:00:35.480 --> 00:00:36.280
Just briefly

00:00:37.480 --> 00:00:39.480
This panel is divided into
two main parts

00:00:39.480 --> 00:00:40.360
In the first part,

00:00:40.640 --> 00:00:42.480
we will discuss three main subtopics

00:00:42.480 --> 00:00:44.560
which are closely related to the

00:00:44.960 --> 00:00:46.680
to the topic of the panel 

00:00:47.200 --> 00:00:48.440
Firstly, we will discuss

00:00:48.760 --> 00:00:52.040
the influence of technologies
on our society

00:00:52.360 --> 00:00:54.720
Secondly, we will discuss also 
the positive impact 

00:00:54.920 --> 00:00:58.880
A possible positive impact 
of technologies on our democracy

00:00:59.200 --> 00:01:00.080
And thirdly,

00:01:00.280 --> 00:01:02.880
we will discuss problematic
of internet giants

00:01:02.920 --> 00:01:04.800
and their possible regulation

00:01:05.560 --> 00:01:07.040
In the second part of the panel,

00:01:07.200 --> 00:01:08.920
there will be time for your questions

00:01:09.360 --> 00:01:10.600
Questions from the audience

00:01:10.880 --> 00:01:13.800
Now I'm talking to the audience

00:01:13.960 --> 00:01:15.920
If you have any question
don't hesitate to ask

00:01:16.560 --> 00:01:17.480
in the chatroom

00:01:17.960 --> 00:01:19.600
and in the second part of the panel

00:01:20.040 --> 00:01:24.320
we will get to your questions and
find the answers I hope

00:01:24.640 --> 00:01:30.800
And please I also kindly ask you to mute
your microphones and cameras

00:01:31.760 --> 00:01:33.960
Before we move to discussion itself

00:01:34.320 --> 00:01:37.160
please let me introduce
our dear panelists

00:01:37.360 --> 00:01:41.440
I'm very glad to welcome here
Miss Renata Ávila Pinto

00:01:41.880 --> 00:01:46.000
Who is a Guatemalan international
Human Rights and technology lawyer

00:01:46.400 --> 00:01:47.600
and author 

00:01:47.640 --> 00:01:50.840
and she is also a co-founder and council
member of the

00:01:51.000 --> 00:01:52.440
Progressive international

00:01:53.280 --> 00:01:55.480
and also she is the co-founder

00:01:55.720 --> 00:01:59.200
of the Alliance for
Inclusive Algorithms

00:01:59.640 --> 00:02:02.160
She also defended
WikiLeaks and Julian Assange

00:02:02.520 --> 00:02:04.480
and she is also advisor for

00:02:04.880 --> 00:02:08.640
just digital transformation
against digital colonialism

00:02:10.080 --> 00:02:11.440
Miss Renata Ávila welcome

00:02:16.120 --> 00:02:18.280
I’m also welcoming Mr. Vojtěch Pikal

00:02:19.040 --> 00:02:22.640
who is vice chairman
of the Czech Pirate Party

00:02:22.640 --> 00:02:25.520
and he is also vice chairman of

00:02:25.800 --> 00:02:28.840
the Chamber of Deputies of
the Parliament of the Czech Republic

00:02:29.240 --> 00:02:34.000
where he focuses mainly on elections,
democracies and constitutional affairs

00:02:35.000 --> 00:02:36.080
And last but not least,

00:02:36.080 --> 00:02:38.280
I would also introduce
Mr. Vojtěch Boháč

00:02:38.960 --> 00:02:40.240
Who is a journalist,

00:02:40.240 --> 00:02:41.160
editor-in-chief

00:02:41.160 --> 00:02:44.400
and also co-founder
of the Voxpot project

00:02:44.400 --> 00:02:45.720
where he focuses mainly on

00:02:45.960 --> 00:02:49.560
conflicts, East Europe,
Balkan states or the Near East 

00:02:50.400 --> 00:02:50.920
Hello

00:02:51.880 --> 00:02:53.440
Now we move to discussion itself

00:02:54.600 --> 00:02:55.200
Firstly

00:02:55.760 --> 00:02:59.840
I would like to ask and I turn
to Miss Avila Pinto

00:03:00.640 --> 00:03:01.920
Please, I would like to ask you

00:03:03.200 --> 00:03:04.640
how digital technologies

00:03:04.640 --> 00:03:06.960
especially the internet and
social media

00:03:07.720 --> 00:03:12.040
influence our society and politics
and political environment?

00:03:12.760 --> 00:03:13.720
To be more specific,

00:03:14.560 --> 00:03:17.960
do you think that there is still
a distinction between

00:03:18.280 --> 00:03:20.840
voters and users nowadays?

00:03:22.600 --> 00:03:24.400
I was starting by saying that

00:03:25.040 --> 00:03:28.240
we are facing our democracy's
new inequalities

00:03:28.240 --> 00:03:31.600
and with the very basic issue of
connectivity, for example

00:03:31.600 --> 00:03:35.040
and this situation right now
like illustrates it very well 

00:03:35.040 --> 00:03:35.600
You know, like

00:03:35.920 --> 00:03:37.680
Do the usual,
you know,

00:03:37.680 --> 00:03:39.360
if you are in the center of the city

00:03:39.360 --> 00:03:42.480
and you have access to more services?

00:03:42.480 --> 00:03:44.000
Do you have access to more information?

00:03:44.000 --> 00:03:45.920
Do you have access to the institutions?

00:03:46.240 --> 00:03:49.760
you add now the layer of more distance

00:03:50.080 --> 00:03:52.720
Which is like saw as distance 

00:03:52.720 --> 00:03:55.640
between political parties,
the public administration

00:03:55.880 --> 00:03:58.520
and the people who are left behind

00:03:58.520 --> 00:04:00.240
in areas with poor infrastructure

00:04:00.720 --> 00:04:05.200
Let’s remember that through
all this panel

00:04:05.200 --> 00:04:09.000
because I think that we
take connectivity for granted

00:04:09.480 --> 00:04:12.280
and we take connectivity
and skills for granted

00:04:12.600 --> 00:04:16.400
and then the day that the voters
are casting their ballots,

00:04:16.800 --> 00:04:19.480
we realise that there's
lots of people who

00:04:20.040 --> 00:04:20.680
the message,

00:04:20.680 --> 00:04:24.880
because we relied so heavily
on internet and online,

00:04:27.480 --> 00:04:29.160
we never reached them 

00:04:29.720 --> 00:04:30.720
Our message never

00:04:30.720 --> 00:04:33.120
Progressive politics messages
never reached them

00:04:33.120 --> 00:04:34.200
because we assume

00:04:34.560 --> 00:04:36.280
We take digital as granted

00:04:36.680 --> 00:04:38.360
This is the first thing to remember

00:04:38.800 --> 00:04:42.520
and the first layer of dependency,
I would say 

00:04:43.080 --> 00:04:44.400
How layer of dependency?

00:04:44.400 --> 00:04:46.320
Because when we activate

00:04:46.360 --> 00:04:49.160
and when we do all of
our social activism,

00:04:49.240 --> 00:04:52.080
political activism
and outreach to voters

00:04:52.640 --> 00:04:56.840
using tools that are based
in the US most of the times

00:04:57.280 --> 00:04:58.280
Hosted in the US

00:04:58.440 --> 00:05:00.360
Based in the US and so on 

00:05:01.080 --> 00:05:04.160
We are also creating
a layer of dependency

00:05:04.800 --> 00:05:08.000
of our political movements to data

00:05:08.000 --> 00:05:11.440
and are also being a little bit reckless,
I would say, because

00:05:12.880 --> 00:05:14.000
On the one hand,

00:05:14.000 --> 00:05:16.240
we are using the powerful tools

00:05:16.240 --> 00:05:18.880
that have been developed
in the last years

00:05:19.120 --> 00:05:20.040
to target

00:05:20.160 --> 00:05:21.920
to reach out

00:05:21.920 --> 00:05:26.480
and to expand our bases
and our message

00:05:26.960 --> 00:05:29.120
but we are not doing it in our own

00:05:29.200 --> 00:05:30.560
We are not growing the flowers,

00:05:30.640 --> 00:05:32.040
let’s say the flowers of democracy,

00:05:32.040 --> 00:05:33.240
in our own garden

00:05:33.280 --> 00:05:36.120
We are growing the flowers
for someone else to cut them

00:05:37.120 --> 00:05:38.680
and to kick us out of the garden

00:05:39.040 --> 00:05:42.400
I think that that is
an important thing to remember

00:05:42.400 --> 00:05:45.280
when we think of Facebook,
when we think of Twitter, 

00:05:45.280 --> 00:05:48.880
when we think of most of the tools 
that we are using today

00:05:49.120 --> 00:05:52.240
And it's very interesting that
I'm addressing a European audience

00:05:52.240 --> 00:05:52.800
Because

00:05:53.200 --> 00:05:55.400
In my country,
to be fully honest

00:05:55.400 --> 00:05:59.000
Okay, we could and we have
a small team of engineers

00:05:59.000 --> 00:06:01.400
and we could develop some tools
that are okay-ish 

00:06:01.920 --> 00:06:03.320
But you c’mon Europe

00:06:03.920 --> 00:06:06.280
Europe has all the abilities,

00:06:06.280 --> 00:06:07.600
all the skills

00:06:07.760 --> 00:06:10.160
All the right frames

00:06:10.160 --> 00:06:12.880
to develop their own
technologies for democracy

00:06:12.880 --> 00:06:13.640
and its 

00:06:14.160 --> 00:06:19.120
I think you understand why in 20 years
it didn't happen

00:06:24.040 --> 00:06:25.520
The second thing

00:06:25.520 --> 00:06:26.560
The second layer is the

00:06:28.200 --> 00:06:29.000
The first is connectivity,

00:06:29.000 --> 00:06:30.360
then the technologies that we use

00:06:30.680 --> 00:06:33.360
and the third thing I will say
is regulation

00:06:34.520 --> 00:06:36.200
In spite of GDPR

00:06:36.200 --> 00:06:40.400
and in spite of all the efforts that
the European Union has done

00:06:40.400 --> 00:06:45.920
to shape technology according to
European values 

00:06:46.400 --> 00:06:48.320
The regulation comes too late 

00:06:49.000 --> 00:06:52.040
Because if we wanted to
shield democracies

00:06:52.160 --> 00:06:58.120
and if we wanted to shield the voters

00:06:58.120 --> 00:07:02.000
and if we wanted to shield the process
of free and fair elections

00:07:04.200 --> 00:07:08.280
The moment to regulate is not when
the technologies are already deployed

00:07:08.280 --> 00:07:09.880
but it's in the moment of deciding 

00:07:10.400 --> 00:07:11.920
And I think that

00:07:14.000 --> 00:07:17.920
their regulation came too late
when the extractive mode

00:07:17.920 --> 00:07:22.800
the data extractivism model was
so integrated in the technologies

00:07:22.800 --> 00:07:25.920
that we used to mediate
our political relationships

00:07:26.360 --> 00:07:27.120
That

00:07:28.040 --> 00:07:29.480
we put in the same bucket 

00:07:29.680 --> 00:07:32.280
political relationships,
then personal relationship

00:07:32.280 --> 00:07:35.840
then commercial relationships
with people we connected with

00:07:37.160 --> 00:07:38.800
And what you said like 

00:07:38.800 --> 00:07:41.600
the difference of users and citizens 

00:07:42.320 --> 00:07:44.320
That is precisely the problem because

00:07:44.640 --> 00:07:48.400
the design of most of the technologies
that we use today,

00:07:48.400 --> 00:07:51.720
of the social media technologies
that we use today

00:07:52.080 --> 00:07:52.400
is

00:07:52.920 --> 00:07:53.480
it's that

00:07:53.480 --> 00:07:54.320
is of use

00:07:54.320 --> 00:07:55.560
Of general purpose

00:07:55.560 --> 00:07:56.000
Of use


00:07:56.360 --> 00:07:57.880
In any situation

00:07:58.240 --> 00:08:01.480
And the relationship of a citizen 

00:08:02.360 --> 00:08:04.040
A citizen with other

00:08:04.040 --> 00:08:06.680
or a citizen with
the public administration

00:08:06.680 --> 00:08:08.480
or with the political parties 

00:08:08.720 --> 00:08:16.040
The development and the potential
expansion of the civic life

00:08:17.280 --> 00:08:18.720
It should be shaped

00:08:18.720 --> 00:08:19.920
and it should be designed

00:08:19.920 --> 00:08:22.240
and it should be like deployed

00:08:22.240 --> 00:08:24.520
following different rules

00:08:25.120 --> 00:08:32.040
And that's one of the things I want to
[inaudible]

00:08:32.040 --> 00:08:33.120
I mean, I would maybe

00:08:33.560 --> 00:08:37.840
Maybe a good idea to think of 
a better digital democracy

00:08:37.840 --> 00:08:39.080
would be to think of

00:08:39.880 --> 00:08:42.760
of different spheres of interaction 

00:08:43.120 --> 00:08:47.120
where a person has
its relationship with commerce

00:08:47.120 --> 00:08:50.080
separated by law maybe

00:08:50.440 --> 00:08:53.160
from its relationship with politics

00:08:53.160 --> 00:08:56.040
and not all has to happen
in the same platform 

00:08:57.720 --> 00:09:00.120
Those are like my initial thoughts

00:09:02.560 --> 00:09:06.880
Yeah, of course the problem
that we have today is that

00:09:06.880 --> 00:09:10.320
the technologies that we use
are not framed for users,

00:09:10.480 --> 00:09:11.520
not for citizens

00:09:11.520 --> 00:09:15.200
and not for exercise of full democracy

00:09:16.560 --> 00:09:17.720
Thank you very much for now 

00:09:17.800 --> 00:09:19.760
We will come back to this topic

00:09:20.280 --> 00:09:23.040
We will discuss algorithms and
non-transparent algorithms 

00:09:24.280 --> 00:09:25.120
In a few minutes

00:09:25.360 --> 00:09:27.960
Right now I would like to ask Mr. Pikal 

00:09:28.400 --> 00:09:30.400
You are an active politician 

00:09:30.560 --> 00:09:33.000
You are member of
the Chamber of Deputies

00:09:33.000 --> 00:09:34.440
of the Parliament of
the Czech Republic

00:09:35.080 --> 00:09:37.000
so I would like to ask you

00:09:39.400 --> 00:09:42.680
What's your point of view
when it comes on the question

00:09:42.680 --> 00:09:47.160
How internet technologies influence
voters decision-making?

00:09:48.440 --> 00:09:52.720
Well, we need to understand that
our current democratic system

00:09:52.720 --> 00:09:58.000
as it is built in most republic
nations states,

00:09:58.320 --> 00:09:59.560
as we know it today,

00:09:59.560 --> 00:10:03.800
was built for different sort of
political discussion

00:10:03.800 --> 00:10:06.520
and political decision-making

00:10:06.520 --> 00:10:08.800
that we experience now

00:10:09.360 --> 00:10:10.360
Because

00:10:11.240 --> 00:10:13.920
it is designed that
the political discussion

00:10:13.920 --> 00:10:17.080
because democracy is not only about
distribution of votes

00:10:17.080 --> 00:10:18.080
and how you count them

00:10:18.560 --> 00:10:20.440
It is also about distribution
of speech

00:10:20.440 --> 00:10:22.040
and I think that

00:10:22.960 --> 00:10:26.400
changing environment and changing
internet environment 

00:10:26.800 --> 00:10:27.800
reminds us of that 


00:10:28.200 --> 00:10:33.720
Because now everyone can own
a newspaper of their own

00:10:33.720 --> 00:10:40.200
And the distribution channels are
privately owned by enterprises

00:10:40.200 --> 00:10:45.040
that are here to sell us advertisements

00:10:45.040 --> 00:10:49.960
and use our emotions to keep us
connected to these environments

00:10:49.960 --> 00:10:52.000
That's the reality we face now

00:10:52.000 --> 00:10:52.560
And

00:10:53.400 --> 00:10:56.200
the political system that
we have currently

00:10:56.440 --> 00:11:02.080
is for the voters to follow discussions
that are happening 

00:11:02.520 --> 00:11:05.920
Public discussions that are happening
in the pages of the newspapers

00:11:05.920 --> 00:11:08.920
or on tv screens

00:11:08.920 --> 00:11:13.000
and then maybe have at home
or at some social gatherings

00:11:13.240 --> 00:11:15.200
private discussions about those topics

00:11:15.640 --> 00:11:20.680
But currently the space of political
discussion is very changed

00:11:21.360 --> 00:11:25.000
and I don't think that we can ever

00:11:25.480 --> 00:11:27.600
as what previous mentions

00:11:27.600 --> 00:11:31.160
Changed the rules and the regulations 
of environments

00:11:31.160 --> 00:11:35.360
and the things faster than
they are developed

00:11:36.360 --> 00:11:42.280
Also we are living in the changes
changing ever so faster

00:11:42.800 --> 00:11:48.080
And the regulations will never
be able to catch up with that 

00:11:48.080 --> 00:11:56.360
So we need not to look at these
new mechanics and new realities

00:11:56.360 --> 00:11:58.000
as something completely new 

00:11:58.240 --> 00:12:01.320
We need to adapt a mindset

00:12:01.320 --> 00:12:05.840
in our judicial system and
in our political system

00:12:05.840 --> 00:12:08.800
that everything has already been there

00:12:09.640 --> 00:12:13.120
There was a time where
the printing press was something new

00:12:13.120 --> 00:12:16.880
and we were able to adapt to that

00:12:17.040 --> 00:12:20.000
And there was a time where reading
was something new

00:12:21.400 --> 00:12:22.920
and we were able to adapt to that

00:12:22.920 --> 00:12:26.200
And we need to think of 
those new things that

00:12:26.520 --> 00:12:28.040
political spaces privately owned 

00:12:29.520 --> 00:12:30.520
Some

00:12:30.800 --> 00:12:31.480
In some way

00:12:31.480 --> 00:12:35.000
or that some people are
very much disconnected

00:12:35.000 --> 00:12:38.440
from the places where the political
discussions happens

00:12:38.640 --> 00:12:42.840
because they are not connected
to the internet or to the news

00:12:42.840 --> 00:12:44.640
because they don't have time to go 

00:12:46.360 --> 00:12:48.560
These are all things
that being together,

00:12:48.560 --> 00:12:49.800
being here

00:12:50.560 --> 00:12:51.280
So

00:12:52.760 --> 00:12:58.760
We need to adopt a mindset where
we use previous decisions

00:12:58.760 --> 00:13:01.080
about privacy and about speech

00:13:01.240 --> 00:13:04.680
and just apply them
to the new environment 

00:13:04.680 --> 00:13:10.320
Don't pretend this is something 
completely new

00:13:10.320 --> 00:13:14.840
because there was something completely
new fifty thousand hundred years ago

00:13:14.840 --> 00:13:15.520
or so

00:13:16.880 --> 00:13:17.640
But

00:13:18.920 --> 00:13:20.000
To your question

00:13:22.640 --> 00:13:27.120
I think the parliaments can adapt
to the new systems

00:13:27.560 --> 00:13:31.960
because they are now quite more
connected to the average voter

00:13:31.960 --> 00:13:37.120
because we are daily spammed
as our system of

00:13:37.960 --> 00:13:42.920
As our information system
of the parliament actually

00:13:42.920 --> 00:13:48.280
decided actually to be called with
calls from basic citizen like

00:13:48.760 --> 00:13:53.800
Before if you wrote your representative
in the system we are based on

00:13:53.800 --> 00:13:55.600
you had to write a letter, 
you had to send it

00:13:55.600 --> 00:13:57.480
and it took a few days to reach

00:13:58.000 --> 00:13:59.000
And it was an effort

00:13:59.360 --> 00:14:04.680
Now you can create a webpage
where everyone can register

00:14:04.920 --> 00:14:07.400
and just send their votes
by two clicks of a button

00:14:08.200 --> 00:14:17.160
And that's a new form of connection
between citizens and its representatives

00:14:17.600 --> 00:14:20.120
We are so reached the time where it's

00:14:21.120 --> 00:14:24.960
what does it mean to have
a public political meeting

00:14:24.960 --> 00:14:26.280
has quite changed 

00:14:26.600 --> 00:14:29.720
Because beforehand if there was some
public political meeting 

00:14:29.720 --> 00:14:31.040
where discussion was happening

00:14:31.880 --> 00:14:36.400
If you wanted to know what was happening
you needed to get a time and get there

00:14:36.800 --> 00:14:39.360
to be even able to
witness the discussion

00:14:39.640 --> 00:14:41.760
and for what the politicians
were saying 

00:14:43.760 --> 00:14:44.640
But today 

00:14:45.200 --> 00:14:46.760
the public meeting can be recorded

00:14:47.080 --> 00:14:48.240
and can be stored forever

00:14:48.920 --> 00:14:50.800
and that's a new thing

00:14:51.640 --> 00:14:52.080
And

00:14:52.680 --> 00:14:56.360
Some politicians are quite
not compatible to that

00:14:56.840 --> 00:15:01.200
and that's also because now 

00:15:02.240 --> 00:15:04.040
it's not only the media 

00:15:04.440 --> 00:15:07.760
It can be everyone who can go
and see a meeting

00:15:07.760 --> 00:15:10.080
And if you go to see a meeting, 
a public meeting

00:15:10.360 --> 00:15:12.880
You can be recorded being there
saying something

00:15:13.160 --> 00:15:15.560
Even if you are a private citizen 
not represented

00:15:16.240 --> 00:15:19.360
it's also something that we see as
a new issue

00:15:20.000 --> 00:15:22.760
because now our lives
are kept there forever

00:15:22.920 --> 00:15:24.640
As it was once said

00:15:24.880 --> 00:15:28.920
the internet never forgets
and never forgives

00:15:28.920 --> 00:15:31.000
And that's the reality
we live in now 

00:15:31.880 --> 00:15:35.360
And that's related to the politicians or

00:15:35.520 --> 00:15:40.840
even active citizens need to
be able to be part of

00:15:41.000 --> 00:15:44.720
You need to be able to own
to your previous decisions

00:15:44.920 --> 00:15:46.160
to your previous things

00:15:46.520 --> 00:15:47.360
Okay, Mr. Pikal 

00:15:47.440 --> 00:15:48.120
Thank you for now 

00:15:48.240 --> 00:15:51.880
Now I would like to turn to Mr. Boháč

00:15:51.880 --> 00:15:56.240
and I would jump back to
the topic we discussed earlier

00:15:56.800 --> 00:15:57.680
in this panel

00:15:57.680 --> 00:16:01.080
And this is a topic and
problems or problematic of

00:16:01.560 --> 00:16:03.800
non-transparent algorithms 

00:16:04.200 --> 00:16:08.040
That are used in political campaigns
and political environment

00:16:08.320 --> 00:16:10.640
We all know the
Cambridge Analytica scandal

00:16:10.640 --> 00:16:11.640
Cambridge Analytica used

00:16:12.480 --> 00:16:13.840
collected and misused

00:16:14.840 --> 00:16:15.480
users data,

00:16:15.480 --> 00:16:17.680
personal data of Facebook users

00:16:18.200 --> 00:16:24.280
to political aims and political goals
in political disputes and campaigns

00:16:25.520 --> 00:16:26.800
This kind of behaviour

00:16:27.080 --> 00:16:30.000
and the problems of 
non-transparent algorithms

00:16:30.000 --> 00:16:32.560
and how to say, 

00:16:32.640 --> 00:16:37.240
behavioural profiling of
the users and of the voters

00:16:38.840 --> 00:16:39.480
That's

00:16:39.840 --> 00:16:40.680
what is 

00:16:41.440 --> 00:16:42.800
Why is they are

00:16:43.160 --> 00:16:47.920
We can see the creating of the
so called closed bubbles 

00:16:47.920 --> 00:16:51.440
and alternative realities
in the public spaces 

00:16:53.040 --> 00:16:55.280
So I'm asking you Mr. Boháč
as a journalist

00:16:56.040 --> 00:16:58.520
Do social media and media in general

00:16:58.840 --> 00:16:59.680
and internet

00:17:00.120 --> 00:17:02.160
divide society

00:17:02.960 --> 00:17:05.720
instead of bringing it closer together?

00:17:06.120 --> 00:17:08.000
And what's the solution?

00:17:09.680 --> 00:17:11.680
If I will come back

00:17:11.760 --> 00:17:13.200
I see a big problem if,

00:17:14.080 --> 00:17:14.800
as we discussed,

00:17:14.800 --> 00:17:17.520
there are non-transparency
of algorithms

00:17:17.520 --> 00:17:21.640
and different purpose of
different social media

00:17:21.640 --> 00:17:23.480
or different platforms

00:17:24.480 --> 00:17:26.120
when like it's like kind of

00:17:27.200 --> 00:17:28.640
a question about like free will

00:17:28.640 --> 00:17:29.960
Whether we have it here

00:17:29.960 --> 00:17:32.120
and whether we can decide
about ourselves

00:17:33.120 --> 00:17:36.280
in a condition where we don't really
know the algorithms

00:17:36.280 --> 00:17:38.840
which are shaping our behaviour


00:17:39.080 --> 00:17:43.800
And in conditions where algorithms
changes like every now and then

00:17:44.720 --> 00:17:47.440
It can change non-transparently
in a minute

00:17:47.960 --> 00:17:50.880
And that's the problem that we face

00:17:50.880 --> 00:17:53.680
because internet per se is,

00:17:54.200 --> 00:17:55.680
at least definitely for media,

00:17:55.680 --> 00:18:01.200
a great space to spread
good quality information

00:18:01.200 --> 00:18:04.920
or to let anyone write

00:18:04.920 --> 00:18:07.440
if he or she has something to say 

00:18:08.000 --> 00:18:11.480
But then like what we face
are like algorithms

00:18:11.880 --> 00:18:15.840
in which we like jump in a water
which we don't fully understand

00:18:15.840 --> 00:18:18.000
and we don't know how to swim there

00:18:18.160 --> 00:18:21.400
and how to plan for longer time 

00:18:21.680 --> 00:18:23.080
And that's the question of free will 

00:18:23.080 --> 00:18:26.600
because how we behave,

00:18:26.600 --> 00:18:27.520
what we consume,

00:18:27.520 --> 00:18:28.240
how we vote 

00:18:28.760 --> 00:18:31.840
depends on the context in which
we understand ourselves

00:18:32.800 --> 00:18:33.200
And

00:18:33.960 --> 00:18:35.200
On social media

00:18:35.200 --> 00:18:38.560
with a small group of owners

00:18:38.960 --> 00:18:41.560
or with non-transparent algorithms

00:18:41.880 --> 00:18:44.480
it's not really possible to plan
for a long time 

00:18:44.480 --> 00:18:46.760
and it’s the same for
like being citizens

00:18:47.360 --> 00:18:49.400
or like being like journalists having

00:18:50.280 --> 00:18:53.960
or like being politicians maybe

00:18:54.840 --> 00:18:58.880
The problem is that the context
in which we act

00:18:59.480 --> 00:19:01.760
can change according to the will 

00:19:01.760 --> 00:19:06.720
of the usually super rich owners
of the platform

00:19:06.720 --> 00:19:10.600
And that's what I see as
a big problem nowadays

00:19:10.600 --> 00:19:16.720
and like which hinders to be a
like citizen becomes citizenship

00:19:16.720 --> 00:19:19.840
and like politics is about
long period planning,

00:19:20.120 --> 00:19:21.120
the same as,

00:19:21.360 --> 00:19:24.200
like it's also how media should act

00:19:24.320 --> 00:19:29.120
How we should work to
be able to foresee

00:19:29.360 --> 00:19:31.120
or to see to the future

00:19:31.120 --> 00:19:36.000
and put people and things that are
going on into some broader context

00:19:36.000 --> 00:19:37.200
Well it's quite difficult

00:19:37.240 --> 00:19:38.480
when we can’t plan

00:19:38.840 --> 00:19:41.040
because somebody does it for us

00:19:41.040 --> 00:19:43.440
Somebody makes this

00:19:44.160 --> 00:19:45.160
I call it sometimes like

00:19:46.280 --> 00:19:47.760
This changes in algorithms 

00:19:48.600 --> 00:19:50.160
Like small short doctrines

00:19:50.160 --> 00:19:52.520
Which just makes people confused

00:19:52.520 --> 00:19:55.600
because they don't know the context
in which they appear

00:19:55.600 --> 00:19:58.120
because of some small change
in Facebook or Twitter

00:19:58.360 --> 00:19:59.480
or wherever

00:20:00.040 --> 00:20:02.560
Which we have to adapt again and again

00:20:02.880 --> 00:20:04.920
and focus mostly on adapting

00:20:04.920 --> 00:20:08.080
in the new environment which we face

00:20:08.400 --> 00:20:13.360
and not to some longer term
values of work 

00:20:13.800 --> 00:20:15.520
So yeah


00:20:16.040 --> 00:20:16.760
Thank you very much

00:20:16.880 --> 00:20:21.200
Now I would like to ask
Miss Renata Avila again

00:20:21.680 --> 00:20:22.400
And

00:20:24.360 --> 00:20:28.920
In your work, you also are focused on
transparency of algorithms

00:20:29.720 --> 00:20:31.480
and there are used
on all of your platforms

00:20:31.720 --> 00:20:34.960
And you also mentioned regulation

00:20:34.960 --> 00:20:38.080
Regulation that maybe
it's too late for regulation

00:20:38.280 --> 00:20:39.520
But I'm asking you

00:20:39.800 --> 00:20:43.200
do you think that regulations is
the good way how to

00:20:43.760 --> 00:20:44.760
How to fight 

00:20:45.000 --> 00:20:52.560
Or how to fight against non-transparent
algorithms and microtargeting?

00:20:52.880 --> 00:20:53.600
And

00:20:54.000 --> 00:20:56.520
how this kind of regulation
should look like?

00:20:57.400 --> 00:20:58.360
It's very difficult 

00:20:58.360 --> 00:21:01.200
I mean, 
there is plenty plenty of papers

00:21:01.200 --> 00:21:04.760
questioning transparency
as the ideal solution

00:21:04.760 --> 00:21:09.400
And it is like the burden is
placed basically on

00:21:10.200 --> 00:21:12.240
institutions that are already
like, you know

00:21:12.240 --> 00:21:15.400
We have seen the
implementation of GDPR

00:21:15.400 --> 00:21:18.560
if you have lots of resources,
you can implement well

00:21:18.560 --> 00:21:22.040
If you have constrained resources
due to austerity

00:21:22.040 --> 00:21:27.600
and now we will see them with
the imminent economic crisis

00:21:27.600 --> 00:21:29.720
coming around the corner

00:21:32.760 --> 00:21:35.960
The institutions to enforce
the regulation

00:21:35.960 --> 00:21:36.520
I mean,

00:21:37.040 --> 00:21:38.280
let's start for something

00:21:38.840 --> 00:21:41.320
Social media companies 
are taking full advantage

00:21:41.320 --> 00:21:45.960
of our intense engagement
and political engagement online 

00:21:46.960 --> 00:21:51.080
They barely pay taxes
in the European Union 

00:21:52.480 --> 00:21:53.480
On top of that,

00:21:54.120 --> 00:21:58.440
The damage and the disruption
and the difficulties

00:21:58.440 --> 00:22:01.560
that they are putting our
electoral authorities into

00:22:01.560 --> 00:22:04.240
and the political parties into 

00:22:05.560 --> 00:22:09.040
Because of the obscurity
of the algorithms

00:22:09.240 --> 00:22:11.080
are making the institutions 

00:22:13.120 --> 00:22:16.920
and are forcing the institutions to
allocate even more public money

00:22:16.920 --> 00:22:19.520
into scrutinizing their actions

00:22:21.240 --> 00:22:22.920
On top of that,

00:22:23.640 --> 00:22:25.920
It is the same question
of all the transparency

00:22:25.920 --> 00:22:28.920
and the audity opening
those black boxes

00:22:28.920 --> 00:22:34.480
will guarantee us that we can actually
do something about it

00:22:34.480 --> 00:22:36.920
because it's something that is
constantly changing

00:22:36.920 --> 00:22:38.840
and requires constant supervision

00:22:39.880 --> 00:22:44.680
I know that I will suggest
something quite radical 

00:22:44.680 --> 00:22:49.880
But maybe we need to put a stop on

00:22:49.880 --> 00:22:52.360
the use of social media for political purposes

00:22:52.360 --> 00:22:54.040
Maybe we should, you know, like

00:22:54.360 --> 00:22:55.600
maybe a very radical,

00:22:55.600 --> 00:22:58.440
a very very very radical measure

00:22:58.440 --> 00:23:02.840
will be to ban social media 
in political campaigns fully 

00:23:03.160 --> 00:23:09.600
Or social media based in a country
that we cannot regulate

00:23:10.160 --> 00:23:13.880
I think that an interim

00:23:13.880 --> 00:23:15.360
and that's radical of course,


00:23:15.360 --> 00:23:18.080
the radical thing

00:23:18.080 --> 00:23:22.840
that you could only use social media
that is fully transparent

00:23:23.160 --> 00:23:27.400
and that doesn't have algorithms
suggesting things to voters

00:23:27.680 --> 00:23:30.840
and that is hosted locally
or at least in the EU

00:23:30.840 --> 00:23:33.520
That would be a super radical measure

00:23:34.320 --> 00:23:39.160
but maybe an interim point would be
to regulate these companies from the

00:23:39.160 --> 00:23:40.000
I mean

00:23:40.000 --> 00:23:43.240
Elections and electoral laws
are public laws

00:23:43.880 --> 00:23:47.480
And maybe an middle point of it
would be like to

00:23:47.960 --> 00:23:51.600
ask at least during a political campaign
to deactivate

00:23:51.600 --> 00:23:52.600
and not to be

00:23:52.760 --> 00:23:54.680
First, that they cannot sell ads 

00:23:55.360 --> 00:23:59.200
Not disclosing the ads really
is not making a big difference

00:23:59.200 --> 00:24:00.560
when they cannot sell ads

00:24:00.880 --> 00:24:03.440
And second,
that they deactivate algorithms

00:24:04.200 --> 00:24:07.320
showing  some things and hiding
other things during the political 

00:24:07.560 --> 00:24:13.040
At least the most intense
political campaign period

00:24:13.040 --> 00:24:15.760
Because what's happening now is

00:24:17.280 --> 00:24:19.560
is really murky 

00:24:19.560 --> 00:24:20.920
Because we can be

00:24:20.920 --> 00:24:23.960
Like all of us, we can be all Pirates
for example

00:24:23.960 --> 00:24:25.440
and be at the same table

00:24:25.440 --> 00:24:30.160
and be connected to the same
Wi-Fi connecting point

00:24:30.840 --> 00:24:37.120
and we will be seeing as absolutely
different things on our screens

00:24:37.640 --> 00:24:39.920
Even with the same
political orientation 

00:24:39.920 --> 00:24:42.560
And that is the end of politics

00:24:42.560 --> 00:24:44.880
Personalised politics is
the end of politics

00:24:44.880 --> 00:24:48.360
because it's the end of
a common sphere,

00:24:48.640 --> 00:24:52.400
a common space of dialogue
and a shared political plan

00:24:53.480 --> 00:24:57.560
and a common understanding of 
the political affair of your party

00:24:58.080 --> 00:25:02.840
I know that it sounds quite radical
this position

00:25:02.840 --> 00:25:07.280
but I don't think that social media
as it is now 

00:25:07.560 --> 00:25:09.800
Which is highly concentrated,

00:25:09.800 --> 00:25:11.120
completely obscure,

00:25:11.440 --> 00:25:13.520
completely tax irresponsible

00:25:13.920 --> 00:25:17.360
and data intense

00:25:17.720 --> 00:25:20.600
I don't think that it is bringing
any good to our democracies

00:25:20.600 --> 00:25:21.840
I don't think that it is

00:25:21.960 --> 00:25:26.400
The day’s past when it was
an equalizer for small parties

00:25:27.080 --> 00:25:28.080
And

00:25:30.040 --> 00:25:37.800
Now it’s those who can afford a
sophisticated data infrastructure,

00:25:38.360 --> 00:25:40.280
those who are like winning elections


00:25:40.280 --> 00:25:44.520
And sadly it's not necessarily the
most democratic side of politics

00:25:44.680 --> 00:25:46.280
the one taking full advantage of it

00:25:46.640 --> 00:25:47.640
And we cannot own it

00:25:47.640 --> 00:25:49.040
and we are with the hands tied

00:25:49.120 --> 00:25:53.120
and we will be even with more
hands tied with the next generation

00:25:53.120 --> 00:25:56.120
of pre-created agreements
that will completely impede us

00:25:56.600 --> 00:26:01.000
even analysed by a judge

00:26:01.200 --> 00:26:02.600
that could

00:26:03.000 --> 00:26:04.760
that's running these systems

00:26:05.280 --> 00:26:06.200
Thank you
Thank you very much

00:26:07.280 --> 00:26:08.000
Mr. Pikal,

00:26:08.400 --> 00:26:11.680
Renata Avila talked about
internet giants

00:26:11.960 --> 00:26:15.120
and that they are getting more
and more powerful

00:26:15.520 --> 00:26:17.920
when it comes to shaping public opinions

00:26:19.240 --> 00:26:21.000
In your point of view Mr. Pikal,

00:26:22.040 --> 00:26:24.760
how to democratise or decentralise

00:26:25.760 --> 00:26:30.560
the internet or the internet giants
that are so powerful

00:26:30.560 --> 00:26:34.200
in shaping our public opinion
and our companies?

00:26:38.600 --> 00:26:39.920
Thank you for the question


00:26:40.160 --> 00:26:43.400
Well I think it's not only about 
transparency

00:26:43.400 --> 00:26:47.040
because if you have transparency

00:26:47.040 --> 00:26:49.920
how your newsfeed is formated

00:26:52.480 --> 00:26:53.920
Well, you know

00:26:55.000 --> 00:26:58.440
but unless you have power 
over how your newsfeed is formated 

00:26:59.000 --> 00:27:00.720
Actual power that you can decide

00:27:00.720 --> 00:27:02.040
I don't want to see this

00:27:02.840 --> 00:27:06.040
and you know what your actions bring

00:27:06.600 --> 00:27:07.840
There was always this

00:27:07.880 --> 00:27:11.240
whether where my newsfeed should
be formed from the latest

00:27:11.240 --> 00:27:14.040
or from the most recent

00:27:14.040 --> 00:27:15.360
or from the most engaging

00:27:15.400 --> 00:27:15.920
because

00:27:17.240 --> 00:27:22.080
We need to understand
that the social media

00:27:23.840 --> 00:27:26.040
are there not to like inform us

00:27:26.040 --> 00:27:28.120
or create some opinions

00:27:28.120 --> 00:27:31.880
And if we try to make them to say

00:27:31.880 --> 00:27:35.200
“No you don't, 
you can't like just be

00:27:35.200 --> 00:27:38.080
you need to inform people
on the right opinions

00:27:38.320 --> 00:27:40.040
I think it's the bad approach

00:27:40.040 --> 00:27:43.120
because you just perpetrated
the media giants

00:27:43.120 --> 00:27:44.480
You just create them,

00:27:44.720 --> 00:27:46.160
give them more platform,

00:27:46.160 --> 00:27:47.760
give them more power 

00:27:48.480 --> 00:27:49.160
But

00:27:49.760 --> 00:27:52.880
You need to give the power
to the people 

00:27:53.200 --> 00:27:54.640
The people need to decide that

00:27:54.640 --> 00:27:59.480
I don't want and I don't need
to be on this media giant

00:27:59.920 --> 00:28:02.360
I want to have power over my news

00:28:02.360 --> 00:28:07.680
because your reality that informs 
your opinions and your decision-making

00:28:07.880 --> 00:28:12.520
is created by the news you consume

00:28:12.960 --> 00:28:14.480
This is nothing new that

00:28:14.480 --> 00:28:17.320
we all see different realities
in different news

00:28:17.520 --> 00:28:18.920
It was always there

00:28:18.960 --> 00:28:21.400
You just decided what
news channel you watched,

00:28:21.400 --> 00:28:24.840
You decided what
newspapers you buy,

00:28:24.960 --> 00:28:25.880
what you read

00:28:26.400 --> 00:28:28.800
If you read a sports section only
or not 

00:28:30.400 --> 00:28:33.720
And we kinda had this before

00:28:33.720 --> 00:28:34.400
because

00:28:35.440 --> 00:28:39.280
if your chief and leader tells you
that those people over there

00:28:39.280 --> 00:28:41.800
eat babies and are satanic worshippers

00:28:42.360 --> 00:28:44.960
you have no problem with
going at war with them

00:28:45.560 --> 00:28:46.960
But if you

00:28:48.600 --> 00:28:51.000
actually meet them and learn

00:28:51.440 --> 00:28:52.480
what's their experience

00:28:52.480 --> 00:28:54.080
maybe you can understand them

00:28:54.080 --> 00:28:56.480
and maybe you can learn that 
they are actually not worshippers

00:28:56.480 --> 00:28:58.040
They just worship a different god

00:28:58.040 --> 00:28:59.760
which is as false as your own 

00:29:01.720 --> 00:29:03.560
So the seclusion of people

00:29:03.560 --> 00:29:05.640
and creating of tribes

00:29:06.040 --> 00:29:07.040
it's nothing new

00:29:07.360 --> 00:29:08.240
but it is

00:29:09.360 --> 00:29:11.720
We are now secluded in our nations

00:29:11.800 --> 00:29:16.960
We are now secluded within our groups

00:29:16.960 --> 00:29:18.120
and it's the new

00:29:18.120 --> 00:29:22.200
Because your neighbour has
a completely different

00:29:23.560 --> 00:29:25.320
framework of reality than you

00:29:25.480 --> 00:29:27.960
because you don't go to
the same church 

00:29:28.200 --> 00:29:31.160
You are not listening to
the same news

00:29:31.280 --> 00:29:33.360
You are seeing completely
different news

00:29:33.400 --> 00:29:38.640
based on your opinions 
and on what ad revenue

00:29:39.040 --> 00:29:40.480
which you best generate

00:29:40.960 --> 00:29:43.600
So I think the thing we need to do

00:29:43.760 --> 00:29:47.080
is to give the users or people power

00:29:47.480 --> 00:29:49.240
to get away from the media,

00:29:49.400 --> 00:29:52.120
to own your data to decide

00:29:52.240 --> 00:29:54.960
what your data goes where

00:29:55.360 --> 00:29:56.960
and it's kind of literacy

00:29:57.640 --> 00:29:59.640
Because everything is political

00:29:59.800 --> 00:30:00.960
Moving is political 

00:30:01.240 --> 00:30:05.760
Decisions on whether or not
we should map trees

00:30:05.760 --> 00:30:09.920
and see where tree fruit grows

00:30:10.120 --> 00:30:10.880
is political 

00:30:11.120 --> 00:30:12.720
It's about how we shape society

00:30:12.760 --> 00:30:14.280
So you can't say

00:30:14.920 --> 00:30:16.440
There can’t be anything political

00:30:16.520 --> 00:30:18.360
because you can make
anything political

00:30:18.880 --> 00:30:19.880
The colour of your shirt

00:30:20.400 --> 00:30:21.640
you can make it political

00:30:22.640 --> 00:30:26.880
So if we want to combat this

00:30:27.240 --> 00:30:31.080
I think that people need
to own their data

00:30:31.080 --> 00:30:32.640
and own their profiles 

00:30:32.760 --> 00:30:33.200
They can

00:30:33.280 --> 00:30:36.200
They should be able to decide
to disregard them

00:30:36.400 --> 00:30:40.320
They should be able to take them
and move them elsewhere to go 

00:30:40.800 --> 00:30:42.200
And this is the problem, I think

00:30:42.200 --> 00:30:48.080
that the landscape of social media

00:30:48.080 --> 00:30:51.600
or political space or social space

00:30:51.960 --> 00:30:54.240
is completely monopolised by now

00:30:54.600 --> 00:30:58.160
And there are two ways to destruct them

00:30:58.160 --> 00:31:04.640
You can either buy the monopoly
as we did before

00:31:04.960 --> 00:31:06.600
Or you can break it down 

00:31:06.960 --> 00:31:08.200
There's also a third option

00:31:08.200 --> 00:31:11.800
You can build a public infrastructure 

00:31:12.720 --> 00:31:16.360
Because if this is an infrastructure
that is currently needed

00:31:16.360 --> 00:31:20.680
and our democracy cant function
without it properly

00:31:20.680 --> 00:31:27.120
You can't be properly connected to the
societal discourse from social media

00:31:27.240 --> 00:31:30.160
Then there needs to be
public social media,

00:31:30.160 --> 00:31:30.960
publicly owned

00:31:30.960 --> 00:31:34.560
As we have publicly owned televisions,

00:31:34.920 --> 00:31:36.320
public broadcast 

00:31:36.480 --> 00:31:38.240
You need to have public social media

00:31:38.320 --> 00:31:40.560
That's like three options we have


00:31:41.240 --> 00:31:43.200
I really don't think the taxes
will solve that

00:31:43.800 --> 00:31:44.800
Thank you very much

00:31:44.920 --> 00:31:45.440
Now

00:31:45.800 --> 00:31:49.960
Mr. Boháč, I would follow the force
of Mr. Pikal

00:31:50.160 --> 00:31:53.080
and what's your opinion when
it comes to internet giants?

00:31:53.080 --> 00:31:54.840
Do you think that they are too powerful?

00:31:54.840 --> 00:31:56.280
And do you think 

00:31:56.280 --> 00:32:00.320
Do you believe that they are shaping
our democracy?

00:32:01.000 --> 00:32:03.960
And do you think that it's bad?

00:32:04.320 --> 00:32:05.600
And should it be regulated?

00:32:05.920 --> 00:32:08.600
Yeah, it's probably going to be
boring with me

00:32:08.600 --> 00:32:12.400
But I can agree with Vojtěch Pikal

00:32:13.360 --> 00:32:17.280
Because as we see it now
like digital platforms

00:32:17.600 --> 00:32:18.080
I can

00:32:18.440 --> 00:32:20.360
it’s easy to understand

00:32:20.360 --> 00:32:24.120
because with internet
as a quite new thing 

00:32:25.080 --> 00:32:26.960
We appeared in the world
which we, like

00:32:27.720 --> 00:32:30.720
in the time of new platforms
nobody understood like

00:32:31.480 --> 00:32:33.840
what kind of shift it is

00:32:33.840 --> 00:32:35.960
but like now we have

00:32:36.640 --> 00:32:38.440
people or owners of platforms

00:32:38.920 --> 00:32:42.080
who profit from like everything

00:32:42.080 --> 00:32:45.320
what was done without their
investment in that

00:32:45.440 --> 00:32:49.880
Like having like billions of people 
who are able to create content 

00:32:50.360 --> 00:32:53.960
Who can write posts or make pictures 

00:32:53.960 --> 00:32:58.640
Who can post online all this
environment of media

00:32:58.640 --> 00:33:01.200
which are partly dependent on having 

00:33:01.600 --> 00:33:03.480
Or sharing it on social media

00:33:03.680 --> 00:33:06.600
Like it's not something they created

00:33:06.600 --> 00:33:08.800
It's not something like
Facebook invested in

00:33:08.800 --> 00:33:14.640
to have all these infrastructures ready
for people to upload content

00:33:14.720 --> 00:33:16.920
and they just monetise from it 

00:33:17.600 --> 00:33:20.880
So I think that it's possible

00:33:20.880 --> 00:33:24.000
that it only happened because
it was kind of a big shock

00:33:24.240 --> 00:33:26.640
but now it's definitely
a time to talk about

00:33:26.640 --> 00:33:27.680
like how to change it

00:33:27.680 --> 00:33:31.400
and how to make it more fair probably

00:33:34.240 --> 00:33:37.200
And how to make them

00:33:38.040 --> 00:33:38.600
Maybe 


00:33:39.360 --> 00:33:43.280
Don't know exactly whether I am
for like public social networks

00:33:43.280 --> 00:33:49.080
But definitely I'm pro or for
ownership of my data

00:33:49.160 --> 00:33:51.600
which I gave to some platform

00:33:51.720 --> 00:33:56.680
and to be able to withdrawn it again
as fast as I can

00:33:56.880 --> 00:33:59.760
and put it to another social network

00:34:00.040 --> 00:34:02.080
But like the problem nowadays is

00:34:02.080 --> 00:34:05.440
that like the area is
totally monopolised

00:34:05.760 --> 00:34:09.120
and that we should have
different social networks

00:34:09.400 --> 00:34:12.120
with basically the same principles

00:34:12.120 --> 00:34:13.760
Maybe probably with open algorithms

00:34:14.000 --> 00:34:14.800
where I can move

00:34:14.800 --> 00:34:16.840
and if I don't like anymore 

00:34:18.480 --> 00:34:21.720
When I'm informed about the algorithm
of Facebook, for example

00:34:21.720 --> 00:34:26.880
to be able to withdraw all my content
I've been making for

00:34:26.880 --> 00:34:28.760
the last ten years already probably 

00:34:29.000 --> 00:34:31.120
and put it to another place

00:34:31.120 --> 00:34:35.280
because, as I said,
nobody was paid for doing this

00:34:35.280 --> 00:34:40.160
Or like to force those platforms
to share their profits

00:34:40.360 --> 00:34:42.840
from what we created before

00:34:44.120 --> 00:34:47.520
And then I think also like
in competition

00:34:47.640 --> 00:34:49.720
it can be the same as normal media

00:34:49.920 --> 00:34:51.680
That we have like a few private 

00:34:51.680 --> 00:34:55.800
We have one like public
social network per country

00:34:55.800 --> 00:34:58.560
or per I don't know,
maybe in the European Union

00:34:58.680 --> 00:35:01.840
because I don't really like
this country boundaries

00:35:01.880 --> 00:35:04.200
but then it's up to us to discuss

00:35:04.800 --> 00:35:06.680
what are the right boundaries like

00:35:07.520 --> 00:35:09.880
in which social media should work 

00:35:09.880 --> 00:35:16.160
There is this idea of Wikipedia to have
like a social network as well

00:35:16.160 --> 00:35:17.880
which would be much more democratic 

00:35:18.480 --> 00:35:19.480
I like it a lot 

00:35:19.480 --> 00:35:23.680
And I think that like also
we can also see in media landscape

00:35:23.960 --> 00:35:27.160
that if you have many different
media ownerships

00:35:27.240 --> 00:35:32.720
and it's not concentrated around
media enhance of oligarchs

00:35:33.000 --> 00:35:35.120
but you have different types 

00:35:35.240 --> 00:35:39.440
For example, yeah you can have media
owned by big money

00:35:39.680 --> 00:35:41.280
but also like public media

00:35:41.280 --> 00:35:46.040
and also good environment to
flourish for like smaller media

00:35:46.640 --> 00:35:52.360
targeted on ideological viewpoints
of the world

00:35:52.560 --> 00:35:53.920
or different things

00:35:53.920 --> 00:36:00.480
So I think the same environment should
exist also in the social media world

00:36:00.920 --> 00:36:05.840
where everybody can choose where
he or she would like to exist

00:36:07.080 --> 00:36:07.760
Okay, thank you very much 

00:36:08.080 --> 00:36:09.440
It's very interesting this divide

00:36:10.040 --> 00:36:10.520
Maybe

00:36:10.880 --> 00:36:12.560
I would ask Miss Renata Avila

00:36:12.560 --> 00:36:17.120
because I noticed that you agreed 
with the thought of Mr. Pikal

00:36:18.640 --> 00:36:25.040
when it comes to publicly owned
social platforms or online platforms

00:36:25.280 --> 00:36:26.280
and social media 

00:36:27.280 --> 00:36:29.520
But for some people I think

00:36:29.520 --> 00:36:31.400
it sounds maybe little bit scary

00:36:31.840 --> 00:36:32.280
you know,

00:36:32.280 --> 00:36:37.960
to imagine that state or public owned
some online media

00:36:37.960 --> 00:36:40.720
it's against free market and so on

00:36:41.880 --> 00:36:43.600
How do you think it should look like

00:36:44.160 --> 00:36:44.640
You know,

00:36:44.760 --> 00:36:46.960
this kind of ownership
of social media?

00:36:47.320 --> 00:36:51.800
We were not successful actually
anywhere in the world

00:36:51.920 --> 00:36:54.600
to have good public media

00:36:54.800 --> 00:36:56.640
Good public media that is plural

00:36:56.640 --> 00:36:58.480
That is well funded

00:36:58.480 --> 00:36:59.800
That is high quality 

00:37:00.240 --> 00:37:02.840
That is respectful of diversity,

00:37:02.840 --> 00:37:04.840
respectful of the intelligence
of people

00:37:04.840 --> 00:37:07.800
Because one of the things
that I want to highlight here

00:37:08.480 --> 00:37:09.840
Which is also important

00:37:09.840 --> 00:37:12.960
is that ten years ago, you know,
we were saying

00:37:13.640 --> 00:37:15.160
Information power to the people 

00:37:15.160 --> 00:37:16.440
And people are intelligent

00:37:16.440 --> 00:37:17.720
and people can decide

00:37:17.760 --> 00:37:20.720
and people will take information
that the internet is bringing

00:37:20.720 --> 00:37:22.280
and transform the world 

00:37:22.880 --> 00:37:25.960
Ten years later we’re saying
that people are so silly

00:37:25.960 --> 00:37:28.560
That they cannot differentiate
fake from real

00:37:28.840 --> 00:37:29.600
and that they 

00:37:29.880 --> 00:37:31.440
I mean our narratives 

00:37:31.440 --> 00:37:33.440
Or maybe not our narratives

00:37:33.440 --> 00:37:35.160
but media narratives

00:37:35.600 --> 00:37:37.000
Commercial media narratives

00:37:37.480 --> 00:37:39.000
or even state media narratives

00:37:39.280 --> 00:37:41.360
are taking that power back

00:37:41.400 --> 00:37:43.600
even with failed economics models
and saying

00:37:43.760 --> 00:37:47.280
"No no no no, you are not
capable to publish,

00:37:47.280 --> 00:37:48.760
You are not capable to understand"

00:37:49.520 --> 00:37:52.640
And I think that this crisis
that we are into

00:37:52.640 --> 00:37:54.360
which is the democratic crisis 

00:37:54.760 --> 00:37:56.960
Is the perfect opportunity

00:37:56.960 --> 00:37:59.240
that progressive politicians
need to seize

00:37:59.560 --> 00:38:01.560
To reinvent and reimagine

00:38:02.320 --> 00:38:04.400
Reimagine public media 

00:38:04.720 --> 00:38:09.840
And public media of course will have
this component of distribution,

00:38:09.840 --> 00:38:12.400
co-creation, collaboration
and dialogue

00:38:13.160 --> 00:38:13.600
And

00:38:13.840 --> 00:38:18.000
that’s what we need to imagine
in a multidisciplinary way

00:38:18.440 --> 00:38:23.280
And I think that that's also what
needs to be funded with public funds 

00:38:23.840 --> 00:38:26.360
Or maybe with a mix of public
and private funds

00:38:26.360 --> 00:38:32.040
with always guaranteeing power to the
people in terms of data

00:38:32.040 --> 00:38:33.360
So full control of data 

00:38:33.960 --> 00:38:37.720
The ability of communicate in private

00:38:37.840 --> 00:38:42.160
and also the ability to express
opinions anonymously 

00:38:42.840 --> 00:38:44.800
And interoperability,

00:38:44.800 --> 00:38:47.600
so I'm not tied to one single platform

00:38:47.800 --> 00:38:48.680
Plurality 

00:38:48.680 --> 00:38:50.720
So I can express myself
in my own language

00:38:52.440 --> 00:38:55.720
And some sort of self-sovereignty 

00:38:56.600 --> 00:38:57.720
I think that the 

00:38:58.240 --> 00:39:01.240
I don’t have the magic model

00:39:01.600 --> 00:39:04.240
and I think it might take
different shapes

00:39:04.320 --> 00:39:07.360
and it might take different
trials and errors

00:39:07.840 --> 00:39:11.800
but I think it will be very silly
not to start experimenting right now 

00:39:11.800 --> 00:39:15.400
And I think the big opportunity is
to start experimenting

00:39:15.760 --> 00:39:17.520
in this digital social innovation

00:39:17.720 --> 00:39:23.560
that will lead us to proper
21st century public medias

00:39:23.560 --> 00:39:27.000
serving the purposes of informating
the public in a balanced way

00:39:27.000 --> 00:39:31.920
and allowing all voices to have
a chance to express themselves

00:39:31.920 --> 00:39:35.040
and like enabling democracy basically


00:39:35.440 --> 00:39:40.560
I think that the cities can
put some money into it

00:39:43.280 --> 00:39:46.120
to start like pilots at a small level

00:39:46.280 --> 00:39:48.360
I believe in these possibilities

00:39:48.400 --> 00:39:50.400
and I believe that that can be 

00:39:51.280 --> 00:39:54.600
I believe that that can be a vehicle

00:39:55.080 --> 00:39:57.080
towards our independence
from Silicon Valley 

00:39:57.640 --> 00:40:03.360
And I really believe
that it might happen

00:40:04.040 --> 00:40:08.200
the European frame is the
ideal frame for that to happen

00:40:08.760 --> 00:40:09.480
Thank you very much 

00:40:10.280 --> 00:40:13.440
Before we move to our last subtopic,

00:40:13.640 --> 00:40:17.080
I just want to ask Mr. Boháč and
Mr. Pikal if you wanna react to these

00:40:17.280 --> 00:40:21.480
to these ideas of decentralisation
of the social media 

00:40:21.480 --> 00:40:22.160
Yes, Mr. Pikal

00:40:22.320 --> 00:40:26.320
I would just like to add that
internet has no boundaries

00:40:26.440 --> 00:40:31.600
and some public social media platform
operated by state

00:40:32.080 --> 00:40:35.080
just means that you can create
a state network

00:40:35.160 --> 00:40:38.960
that controls the public discourse

00:40:39.440 --> 00:40:43.240
We have states that already censor
their own internet 

00:40:44.120 --> 00:40:46.920
This thing just enhanced so

00:40:47.800 --> 00:40:49.600
you need to be vigilant of that

00:40:49.960 --> 00:40:51.880
And I think that 

00:40:52.520 --> 00:40:54.800
And also I would like to
point out one thing

00:40:54.880 --> 00:40:56.680
We are now four people in a bubble 

00:40:57.480 --> 00:41:01.280
And we don't know if our jokes
land on the audience

00:41:01.360 --> 00:41:06.320
We don't know if what we say is
regarded as good or bad

00:41:07.120 --> 00:41:09.320
With these online discussions,

00:41:10.080 --> 00:41:14.120
we are kinda losing the feedback

00:41:14.520 --> 00:41:18.080
as the public spaces usually have
from the audience

00:41:18.600 --> 00:41:20.560
in form of clapping or booing

00:41:20.760 --> 00:41:22.880
That's something that we are losing

00:41:24.200 --> 00:41:26.520
when we are moving to
democracy of digital 

00:41:26.960 --> 00:41:27.760
And

00:41:29.040 --> 00:41:33.080
that is a thing that I think it
needs to be incorporated

00:41:33.400 --> 00:41:35.400
into the social media to work well

00:41:35.640 --> 00:41:40.640
that you have somehow the 

00:41:41.280 --> 00:41:41.960
Because,

00:41:42.320 --> 00:41:43.160
as it was said,

00:41:45.040 --> 00:41:50.520
in beginning we spoke that information
would be picked up by the crowds

00:41:50.520 --> 00:41:54.960
and we would get good information
to rise to the top 

00:41:55.160 --> 00:42:00.560
But as currently the media
and the social platforms are built,

00:42:00.840 --> 00:42:02.360
they are driven by emotions

00:42:02.400 --> 00:42:05.360
because emotions spread
much better and much faster

00:42:06.000 --> 00:42:10.120
and if we want to have
good digital platforms

00:42:10.120 --> 00:42:11.360
for online discussions,

00:42:11.360 --> 00:42:12.360
for forming opinions,

00:42:12.360 --> 00:42:17.000
for creating the framework
of our society

00:42:17.320 --> 00:42:20.640
they need to be driven not by emotions

00:42:20.880 --> 00:42:24.720
but by information 
and participated discussions

00:42:25.400 --> 00:42:30.480
And for that is, I think,
quite a complicated task

00:42:30.960 --> 00:42:32.360
in form of design 

00:42:33.360 --> 00:42:37.480
And that means that the platforms
would be designed

00:42:37.680 --> 00:42:39.360
with this in mind

00:42:39.760 --> 00:42:46.200
and also the question of who
and how would there be paid

00:42:46.200 --> 00:42:46.960
and profit it 

00:42:47.400 --> 00:42:49.480
This is a difficult one

00:42:49.800 --> 00:42:52.240
because it can't be by ads

00:42:52.240 --> 00:42:54.880
because ads run on emotions

00:42:55.080 --> 00:42:58.040
not on intelligent forms

00:42:58.600 --> 00:42:59.080
Thank you very much 


00:42:59.160 --> 00:42:59.960
If you want to add something 

00:43:00.000 --> 00:43:00.480
Yeah

00:43:00.880 --> 00:43:02.760
I wrote just short notes

00:43:02.760 --> 00:43:05.720
that for me it was like
an interesting idea

00:43:05.720 --> 00:43:06.200
of this like

00:43:08.240 --> 00:43:11.640
public social media on a state level

00:43:11.640 --> 00:43:14.680
because we are just filming
about media in Central Europe

00:43:14.680 --> 00:43:18.600
and out of four countries you have
the public media

00:43:18.800 --> 00:43:20.600
In one country, it doesn't really work 

00:43:20.600 --> 00:43:22.680
In two countries, it's controlled
by governments

00:43:22.840 --> 00:43:24.400
and in one country, 
it's under attack 

00:43:24.400 --> 00:43:27.160
so it's quite sensitive

00:43:27.920 --> 00:43:32.760
thinking about like how to make it
in the principle of all affected

00:43:32.760 --> 00:43:33.520
somehow

00:43:34.200 --> 00:43:36.800
to make social media for people

00:43:36.960 --> 00:43:40.240
who have like more inclination
to communicate with each other

00:43:40.360 --> 00:43:44.720
And not under like strong political
influence in those countries 

00:43:44.840 --> 00:43:51.280
where the democratic tradition
is not that strong

00:43:51.280 --> 00:43:51.640
So

00:43:52.840 --> 00:43:56.600
Then I was thinking, okay,
maybe we still can have something

00:43:57.320 --> 00:43:58.640
what is more global

00:43:58.680 --> 00:44:02.880
but allows different people in different
countries of different interest

00:44:03.600 --> 00:44:04.880
to use for their own 

00:44:04.880 --> 00:44:08.800
But still there is the problem
of control

00:44:09.360 --> 00:44:12.240
which I think has to be addressed

00:44:12.280 --> 00:44:14.240
and will be quite difficult to decide

00:44:14.480 --> 00:44:15.160
Thank you

00:44:16.000 --> 00:44:17.600
Let’s move to other question 

00:44:17.920 --> 00:44:19.120
And the question is 

00:44:19.880 --> 00:44:23.320
Is there some positive impact of
digital technologies on our democracy?

00:44:23.320 --> 00:44:25.760
Because so far we have discussed quite

00:44:25.880 --> 00:44:26.880
I would say, some

00:44:28.480 --> 00:44:29.440
some negative aspects

00:44:29.440 --> 00:44:34.520
But I would also add some positive 
aspects of digital technologies

00:44:34.520 --> 00:44:38.520
and internet technologies
on our democracies

00:44:39.680 --> 00:44:41.480
So Miss Renata Avila

00:44:42.480 --> 00:44:46.320
what positive impacts do you see?

00:44:46.520 --> 00:44:47.520
Yes, of course

00:44:47.840 --> 00:44:48.200
Yeah

00:44:48.720 --> 00:44:49.400
Please answer

00:44:49.840 --> 00:44:52.400
We really have the possibilities to

00:44:53.120 --> 00:44:54.120
for the first time

00:44:54.160 --> 00:44:59.400
massively educate politically
a lot of people

00:44:59.720 --> 00:45:01.800
in a very creative and engaging way

00:45:02.320 --> 00:45:03.920
We shouldn't miss that opportunity

00:45:04.920 --> 00:45:09.400
because that's the key to fix 
all the things digital 

00:45:09.600 --> 00:45:14.880
We have the new generation
fully politically aware

00:45:14.880 --> 00:45:16.600
with critical thinking developed

00:45:16.960 --> 00:45:18.480
and we can even use,
you know,

00:45:18.480 --> 00:45:20.880
we can use all the technologies 
that we have now 

00:45:21.200 --> 00:45:22.400
to reach them out 

00:45:22.960 --> 00:45:25.960
and to prepare them to be critical
about what they are using

00:45:26.360 --> 00:45:29.400
and critical about the importance
of it for the future

00:45:30.280 --> 00:45:31.680
I mean that we are like a

00:45:31.680 --> 00:45:35.760
It's up to us to activate
a political transformation

00:45:35.760 --> 00:45:37.360
that we have never seen before

00:45:37.440 --> 00:45:38.080
Thank you

00:45:38.080 --> 00:45:39.040
Thank you very much

00:45:39.960 --> 00:45:42.560
Now I would turn to Mr. Pikal

00:45:42.920 --> 00:45:46.120
You already mentioned some advantages

00:45:46.480 --> 00:45:49.000
of digital technologies
on our democracy

00:45:49.280 --> 00:45:51.880
but could you highlight some specifics,

00:45:51.880 --> 00:45:53.000
Specific examples

00:45:54.080 --> 00:45:57.320
in which way digital technologies 
and the internet developed

00:45:57.920 --> 00:46:00.240
our democracies in a good way?

00:46:01.320 --> 00:46:04.640
The internet has allowed us 
to be better informed

00:46:05.200 --> 00:46:08.640
and better educated
in all kinds of things

00:46:08.640 --> 00:46:12.120
You can learn almost anything
on the internet

00:46:12.440 --> 00:46:15.240
if you are not lazy to search 

00:46:15.720 --> 00:46:18.960
And this is still true
and will remain true

00:46:20.600 --> 00:46:22.720
And you are able to be
better connected

00:46:23.160 --> 00:46:27.560
We can operate with our colleagues
from different continents,

00:46:27.560 --> 00:46:30.320
from different cultural settings

00:46:31.800 --> 00:46:32.400
easily

00:46:32.600 --> 00:46:35.840
There are great things built like

00:46:36.360 --> 00:46:38.600
Wikipedia or everything

00:46:38.600 --> 00:46:39.240
But 

00:46:40.840 --> 00:46:42.800
We can have better jobs sometimes

00:46:42.800 --> 00:46:44.760
Because now we are better informed

00:46:44.760 --> 00:46:48.440
on some completely new topics

00:46:50.080 --> 00:46:53.600
So I think in regards to
spreading information

00:46:55.040 --> 00:46:56.760
and education as a whole

00:46:57.120 --> 00:47:03.520
Because now more people
can access higher education

00:47:03.520 --> 00:47:06.240
and higher levels of information

00:47:06.600 --> 00:47:07.280
and topics 

00:47:07.320 --> 00:47:08.120
through the internet 

00:47:08.640 --> 00:47:09.680
Through areas

00:47:09.720 --> 00:47:14.280
From further countries 
from all over the world

00:47:15.040 --> 00:47:18.720
And this means more educated people

00:47:18.720 --> 00:47:21.400
and who better understand
the world around them

00:47:22.800 --> 00:47:23.440
And

00:47:25.320 --> 00:47:28.840
you also need to understand that

00:47:28.920 --> 00:47:30.440
people who grew with the internet

00:47:30.440 --> 00:47:33.120
know there's nothing real
on the internet 

00:47:33.280 --> 00:47:35.480
Every girl is a boy 

00:47:35.720 --> 00:47:40.800
Every small girl is a security
intelligence agent

00:47:43.600 --> 00:47:46.840
But people who did not grow
with the change

00:47:48.200 --> 00:47:49.320
need to learn this 

00:47:49.320 --> 00:47:49.720
But

00:47:50.200 --> 00:47:52.920
They learnt in previous times that

00:47:52.920 --> 00:47:55.280
not everything that is said on TV
is true

00:47:55.600 --> 00:47:58.040
That not everything that you read
in the newspaper is true

00:47:58.640 --> 00:48:00.240
And we just need to understand that

00:48:00.240 --> 00:48:02.880
not everything that
your friend sends to you

00:48:02.880 --> 00:48:03.880
through the email

00:48:04.000 --> 00:48:06.240
is true just because
they are friends

00:48:06.520 --> 00:48:07.840
Maybe not even the friends 

00:48:07.840 --> 00:48:11.000
Somebody just takes their email
and is using it as spam

00:48:11.000 --> 00:48:12.160
or just something wrong

00:48:12.400 --> 00:48:14.480
So we need to learn
to be really literate

00:48:14.480 --> 00:48:16.280
about the information that we receive

00:48:16.400 --> 00:48:20.080
That's I think the only thing
that really needs to happen 

00:48:20.080 --> 00:48:21.160
is that we are

00:48:21.400 --> 00:48:24.520
just as some literacy is understood that

00:48:24.520 --> 00:48:27.680
all films and jokes and anything 

00:48:27.720 --> 00:48:29.880
can be political and ridiculise people 

00:48:30.280 --> 00:48:33.520
And also things on the internet 
may be not true

00:48:33.520 --> 00:48:35.640
and can ridiculise people

00:48:36.320 --> 00:48:37.160
It can be not true 

00:48:37.160 --> 00:48:38.520
That's all you need

00:48:40.560 --> 00:48:41.240
Thank you very much 

00:48:41.560 --> 00:48:42.240
Mr Boháč,

00:48:42.840 --> 00:48:43.720
The same question for you 

00:48:43.800 --> 00:48:46.040
Which positives and advantages

00:48:46.280 --> 00:48:49.160
do you see when it comes to influence of

00:48:49.240 --> 00:48:50.760
digital technologies on our democracy?

00:48:51.720 --> 00:48:53.800
Like for me the answer is quite easy

00:48:53.800 --> 00:48:57.400
because I run a online channel

00:48:57.960 --> 00:49:02.160
focused on feature news from abroad

00:49:02.360 --> 00:49:03.400
and now

00:49:03.480 --> 00:49:06.000
Like it wasn't before coronavirus
probably 

00:49:06.000 --> 00:49:08.920
But now we have like
the massive migration into digital

00:49:08.920 --> 00:49:11.000
into online world

00:49:11.600 --> 00:49:19.200
I see that I can really communicate
with people from different places

00:49:19.200 --> 00:49:21.880
and it's normal for me like,
right now

00:49:22.520 --> 00:49:25.000
to get information about
what's going on in

00:49:25.160 --> 00:49:28.680
like East Russia or China
or I don't know Australia

00:49:29.240 --> 00:49:29.880
very easily

00:49:29.880 --> 00:49:31.680
And people are used to like

00:49:31.680 --> 00:49:34.840
in the way of organizing work
as well like

00:49:35.280 --> 00:49:37.840
That I don't have to go everywhere 

00:49:38.280 --> 00:49:39.560
I can study the context

00:49:39.560 --> 00:49:46.480
I can very easily connect with somebody
from like thousands of km away

00:49:46.640 --> 00:49:47.840
and get the context 

00:49:47.840 --> 00:49:52.440
I can ask somebody to walk me through
a city or through a situation

00:49:52.600 --> 00:49:54.400
and explain me what is going on

00:49:54.400 --> 00:49:57.880
and it's definitely like
for the global democracy,

00:49:57.920 --> 00:50:01.120
for kind of for overcoming
national boundaries

00:50:01.120 --> 00:50:02.840
It's something just great

00:50:03.840 --> 00:50:05.760
But then there is also 

00:50:06.640 --> 00:50:08.280
Oh yeah, we should be positive now

00:50:08.400 --> 00:50:08.880
But

00:50:10.240 --> 00:50:14.040
I see that it's awesome
for people who are gifted,

00:50:14.040 --> 00:50:16.680
Who are from like
a good social background,

00:50:16.680 --> 00:50:17.440
Who are active

00:50:17.760 --> 00:50:22.160
But then we have great big gaps

00:50:22.160 --> 00:50:24.800
between who had the opportunity,

00:50:24.800 --> 00:50:26.440
who had the good education 

00:50:26.560 --> 00:50:30.080
and who can like avoid somehow
the algorithms

00:50:30.800 --> 00:50:35.520
just to stick with those online drugs
of social platforms

00:50:35.520 --> 00:50:36.760
where you just consume

00:50:37.360 --> 00:50:40.160
what is like most profitable
for owners of the social 

00:50:40.600 --> 00:50:42.080
Of the digital platforms 

00:50:42.200 --> 00:50:44.160
But like if 

00:50:44.480 --> 00:50:48.280
And then it goes hand in hand
with education 

00:50:48.880 --> 00:50:50.400
How to use the internet 

00:50:50.400 --> 00:50:52.160
And I still think that

00:50:53.240 --> 00:50:55.640
in education there is
a great potential in

00:50:56.640 --> 00:50:59.640
showing people and learning
how to use it

00:50:59.640 --> 00:51:01.040
to give us the best,
so

00:51:01.240 --> 00:51:03.520
But in the end it's definitely a tool

00:51:03.720 --> 00:51:05.280
which just deletes 

00:51:05.640 --> 00:51:07.160
Like can delete any barrier 

00:51:07.480 --> 00:51:10.480
But we have to like fight

00:51:10.480 --> 00:51:13.360
It's not about what's positive
about internet 

00:51:13.360 --> 00:51:15.400
Because internet is the same struggle,

00:51:15.400 --> 00:51:17.320
the same fight as the real life

00:51:17.520 --> 00:51:19.760
where we have to take care that

00:51:19.920 --> 00:51:21.080
like the critical mass,

00:51:21.080 --> 00:51:22.840
the big majority of people

00:51:23.760 --> 00:51:30.760
is not just left to be like
kind of goods for tech giants

00:51:31.960 --> 00:51:32.360
Thank you 

00:51:32.360 --> 00:51:35.560
Thank you very much all for
the participation at this panel

00:51:35.720 --> 00:51:38.080
Unfortunately, our time has passed

00:51:38.560 --> 00:51:39.840
So thank you 

00:51:40.120 --> 00:51:43.520
Thank you very much 
Miss Renata Avila, Mr Pikal and Mr Bohač

00:51:43.880 --> 00:51:45.080
For joining us today

00:51:45.400 --> 00:51:49.320
Thank you to the audience
for being here with us

00:51:49.360 --> 00:51:52.760
and I hope we will see you
again very soon

00:51:52.760 --> 00:51:56.960
and I hope it's gonna be offline
face to face again 

00:51:57.760 --> 00:51:59.160
Have a nice evening

00:51:59.600 --> 00:52:00.280
Thank you very much 

00:52:00.600 --> 00:52:01.600
Thank you to everyone

00:52:01.760 --> 00:52:02.480
Good evening 
